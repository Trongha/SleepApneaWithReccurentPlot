{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done import\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src import config\n",
    "from src import MyUtil as myUtil\n",
    "print('done import')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record for train:  ['a01', 'a02', 'a04', 'a06', 'a07', 'a08', 'a09', 'a11', 'a12', 'a13', 'a14', 'a16', 'a17', 'a18', 'a20', 'b01', 'b02', 'b03', 'b04', 'b05', 'c01', 'c02', 'c03', 'c04', 'c05', 'c06', 'c07', 'c08', 'c09', 'c10']\n",
      "record for test:  ['a03', 'a05', 'a15', 'a10', 'a19']\n",
      "done load RQA\n"
     ]
    }
   ],
   "source": [
    "recordNames = config.NAME_OF_RECORD\n",
    "numRecord = len(recordNames)\n",
    "recordNameForTest = ['a03', 'a05', 'a15', 'a10', 'a19']\n",
    "trainRqa, trainLabel, testRqa, testLabel = myUtil.loadAllRqa(recordNameForTest)\n",
    "print('done load RQA')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainRqa:  (17456, 9)\n",
      "trainLabel:  (17456,)\n",
      "testRqa:  (2413, 9)\n",
      "testLabel:  (2413,)\n",
      "trainLabel unique:  {0: 11330, 1: 6126}\n",
      "testLabel unique:  {0: 1250, 1: 1163}\n"
     ]
    }
   ],
   "source": [
    "print('trainRqa: ', trainRqa.shape)\n",
    "# print(trainRqa[-10:])\n",
    "print('trainLabel: ', trainLabel.shape)\n",
    "print('testRqa: ', testRqa.shape)\n",
    "# print(testRqa[-10:])\n",
    "print('testLabel: ', testLabel.shape)\n",
    "\n",
    "unique, count = np.unique(trainLabel, return_counts=True)\n",
    "print('trainLabel unique: ', dict(zip(unique, count)))\n",
    "unique, count = np.unique(testLabel, return_counts=True)\n",
    "print('testLabel unique: ', dict(zip(unique, count)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': None, 'splitter': 'best'}\n",
      "done fit\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth=6)\n",
    "clf = clf.fit(trainRqa, trainLabel)\n",
    "print(clf.get_params())\n",
    "print('done fit')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testLabel unique:  {0: 1250, 1: 1163}\n",
      "accuracy: 0.824\n",
      "recall: 0.739\n",
      "percision: 0.877\n",
      "confusion_matrix: \n",
      " [[1129  121]\n",
      " [ 303  860]]\n",
      "done Test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "pre = clf.predict(testRqa)\n",
    "accuracy = accuracy_score(testLabel, pre)\n",
    "unique, count = np.unique(testLabel, return_counts=True)\n",
    "print('testLabel unique: ', dict(zip(unique, count)))\n",
    "print(\"accuracy: %.3f\"%accuracy)\n",
    "print('recall: %.3f'%recall_score(testLabel, pre))\n",
    "print('percision: %.3f'%precision_score(testLabel, pre))\n",
    "print('confusion_matrix: \\n', confusion_matrix(testLabel, pre))\n",
    "# print('classification_report: \\n', classification_report(testLabel, pre))\n",
    "print('done Test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a03\n",
      "testLabel unique:  {0: 266, 1: 245}\n",
      "accuracy: 0.830, recall: 0.816, percision: 0.826\n",
      "confusion_matrix: \n",
      " [[224  42]\n",
      " [ 45 200]]\n",
      "a05\n",
      "testLabel unique:  {0: 162, 1: 276}\n",
      "accuracy: 0.799, recall: 0.721, percision: 0.948\n",
      "confusion_matrix: \n",
      " [[151  11]\n",
      " [ 77 199]]\n",
      "a15\n",
      "testLabel unique:  {0: 117, 1: 344}\n",
      "accuracy: 0.787, recall: 0.767, percision: 0.936\n",
      "confusion_matrix: \n",
      " [[ 99  18]\n",
      " [ 80 264]]\n",
      "a10\n",
      "testLabel unique:  {0: 409, 1: 99}\n",
      "accuracy: 0.837, recall: 0.313, percision: 0.674\n",
      "confusion_matrix: \n",
      " [[394  15]\n",
      " [ 68  31]]\n",
      "a19\n",
      "testLabel unique:  {0: 296, 1: 199}\n",
      "accuracy: 0.863, recall: 0.834, percision: 0.826\n",
      "confusion_matrix: \n",
      " [[261  35]\n",
      " [ 33 166]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "for recordName in recordNameForTest:\n",
    "    print(recordName)\n",
    "    testRqa, testLabel, _ = myUtil.loadRqa(recordName, 'test')\n",
    "\n",
    "    unique, count = np.unique(testLabel, return_counts=True)\n",
    "    print('testLabel unique: ', dict(zip(unique, count)))\n",
    "\n",
    "    pre = clf.predict(testRqa)\n",
    "    accuracy = accuracy_score(testLabel, pre)\n",
    "    recall = recall_score(testLabel, pre)\n",
    "    precision = precision_score(testLabel, pre)\n",
    "    print(\"accuracy: {:.3f}, recall: {:.3f}, percision: {:.3f}\".format(accuracy, recall, precision))\n",
    "    print('confusion_matrix: \\n', confusion_matrix(testLabel, pre))\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# pca.fit(trainRqa)\n",
    "# print('done fit')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# transform = pca.transform(trainRqa)\n",
    "# print(transform)\n",
    "#\n",
    "# import matplotlib.pyplot as plt\n",
    "# # print(transform[:, 0])\n",
    "# plt.scatter(transform[:, 0], transform[: ,1], c=trainLabel, label=trainLabel)\n",
    "# plt.legend()\n",
    "# plt.scatter(transform[:, 0], transform[: ,1])\n",
    "# plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
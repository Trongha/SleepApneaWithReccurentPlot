{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done import\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src import config\n",
    "from src import MyUtil as myUtil\n",
    "print('done import')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "recordNames = config.NAME_OF_RECORD\n",
    "numRecord = len(recordNames)\n",
    "numTrain = config.NUMBER_OF_TRAIN_RECORD\n",
    "trainRqa = []\n",
    "trainLabel = []\n",
    "\n",
    "# for iRecord in range(0, numTrain):\n",
    "for iRecord in range(10, 35):\n",
    "    rqa, label, _ = myUtil.loadRqa(recordNames[iRecord], 'train')\n",
    "    trainRqa = np.append(trainRqa, rqa, axis=0) if len(trainRqa) > 0 else rqa\n",
    "    trainLabel = np.append(trainLabel, label, axis=0) if len(trainLabel) > 0 else label\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done load data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "testRqa = []\n",
    "testLabel = []\n",
    "for iRecord in range(25, 26):\n",
    "    rqa, label, _ = myUtil.loadRqa(recordNames[iRecord], 'test')\n",
    "    testRqa = np.append(testRqa, rqa, axis=0) if len(testRqa) > 0 else rqa\n",
    "    testLabel = np.append(testLabel, label, axis=0) if len(testLabel) > 0 else label\n",
    "print('done load data')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainRqa:  (16189, 9)\n",
      "trainLabel:  (16189,)\n",
      "testRqa:  (4362, 9)\n",
      "testLabel:  (4362,)\n",
      "trainLabel unique:  {0: 8440, 1: 7749}\n",
      "testLabel unique:  {0: 3980, 1: 382}\n"
     ]
    }
   ],
   "source": [
    "print('trainRqa: ', trainRqa.shape)\n",
    "# print(trainRqa[-10:])\n",
    "print('trainLabel: ', trainLabel.shape)\n",
    "print('testRqa: ', testRqa.shape)\n",
    "# print(testRqa[-10:])\n",
    "print('testLabel: ', testLabel.shape)\n",
    "\n",
    "unique, count = np.unique(trainLabel, return_counts=True)\n",
    "print('trainLabel unique: ', dict(zip(unique, count)))\n",
    "unique, count = np.unique(testLabel, return_counts=True)\n",
    "print('testLabel unique: ', dict(zip(unique, count)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done fit\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(trainRqa, trainLabel)\n",
    "\n",
    "print('done fit')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done load data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testRqa = []\n",
    "testLabel = []\n",
    "for iRecord in range(25, 26):\n",
    "    rqa, label, _ = myUtil.loadRqa(recordNames[iRecord], 'test')\n",
    "    testRqa = np.append(testRqa, rqa, axis=0) if len(testRqa) > 0 else rqa\n",
    "    testLabel = np.append(testLabel, label, axis=0) if len(testLabel) > 0 else label\n",
    "print('done load data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.78s/trial, best loss: 0.42217418159357634]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.35s/trial, best loss: 0.42217418159357634]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.04s/trial, best loss: 0.4203211859172329]\n",
      "100%|██████████| 4/4 [00:03<00:00,  1.29trial/s, best loss: 0.41692402717726995]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.64trial/s, best loss: 0.41692402717726995]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.95trial/s, best loss: 0.4150710315009265]\n",
      "100%|██████████| 7/7 [00:03<00:00,  1.94trial/s, best loss: 0.4150710315009265]\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.28trial/s, best loss: 0.4150710315009265]\n",
      "100%|██████████| 9/9 [00:03<00:00,  2.52trial/s, best loss: 0.4150710315009265]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.33trial/s, best loss: 0.4150710315009265]\n",
      "{'learner': DecisionTreeClassifier(), 'preprocs': (MinMaxScaler(feature_range=(-1.0, 1.0)),), 'ex_preprocs': ()}\n",
      "param:  {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': None, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# from hpsklearn import HyperoptEstimator, extra_trees\n",
    "# from hyperopt import tpe\n",
    "#\n",
    "# estim = HyperoptEstimator(classifier=clf,\n",
    "#                           algo=tpe.suggest,\n",
    "#                           max_evals=10,\n",
    "#                           trial_timeout=300)\n",
    "# estim.fit(trainRqa, trainLabel)\n",
    "# print(estim.best_model())\n",
    "\n",
    "\n",
    "# print('param: ', clf.get_params())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --------------------------------------\n",
      "testLabel unique:  {0: 12, 1: 469}\n",
      "done load data\n",
      "0.6715176715176715\n",
      "recall:  0.6673773987206824\n",
      "percision:  0.9936507936507937\n",
      "confusion_matrix: \n",
      " [[ 10   2]\n",
      " [156 313]]\n",
      "done Test\n",
      "1 --------------------------------------\n",
      "testLabel unique:  {0: 70, 1: 161}\n",
      "done load data\n",
      "0.45021645021645024\n",
      "recall:  0.2484472049689441\n",
      "percision:  0.8695652173913043\n",
      "confusion_matrix: \n",
      " [[ 64   6]\n",
      " [121  40]]\n",
      "done Test\n",
      "2 --------------------------------------\n",
      "testLabel unique:  {0: 266, 1: 245}\n",
      "done load data\n",
      "0.7808219178082192\n",
      "recall:  0.726530612244898\n",
      "percision:  0.7982062780269058\n",
      "confusion_matrix: \n",
      " [[221  45]\n",
      " [ 67 178]]\n",
      "done Test\n",
      "3 --------------------------------------\n",
      "testLabel unique:  {0: 33, 1: 452}\n",
      "done load data\n",
      "0.8041237113402062\n",
      "recall:  0.8097345132743363\n",
      "percision:  0.976\n",
      "confusion_matrix: \n",
      " [[ 24   9]\n",
      " [ 86 366]]\n",
      "done Test\n",
      "4 --------------------------------------\n",
      "testLabel unique:  {0: 162, 1: 276}\n",
      "done load data\n",
      "0.6940639269406392\n",
      "recall:  0.6268115942028986\n",
      "percision:  0.8480392156862745\n",
      "confusion_matrix: \n",
      " [[131  31]\n",
      " [103 173]]\n",
      "done Test\n",
      "5 --------------------------------------\n",
      "testLabel unique:  {0: 174, 1: 95}\n",
      "done load data\n",
      "0.6691449814126395\n",
      "recall:  0.08421052631578947\n",
      "percision:  0.8\n",
      "confusion_matrix: \n",
      " [[172   2]\n",
      " [ 87   8]]\n",
      "done Test\n",
      "6 --------------------------------------\n",
      "testLabel unique:  {0: 184, 1: 319}\n",
      "done load data\n",
      "0.6361829025844931\n",
      "recall:  0.54858934169279\n",
      "percision:  0.8177570093457944\n",
      "confusion_matrix: \n",
      " [[145  39]\n",
      " [144 175]]\n",
      "done Test\n",
      "7 --------------------------------------\n",
      "testLabel unique:  {0: 305, 1: 189}\n",
      "done load data\n",
      "0.6639676113360324\n",
      "recall:  0.6296296296296297\n",
      "percision:  0.5534883720930233\n",
      "confusion_matrix: \n",
      " [[209  96]\n",
      " [ 70 119]]\n",
      "done Test\n",
      "8 --------------------------------------\n",
      "testLabel unique:  {0: 107, 1: 380}\n",
      "done load data\n",
      "0.45585215605749485\n",
      "recall:  0.3526315789473684\n",
      "percision:  0.8758169934640523\n",
      "confusion_matrix: \n",
      " [[ 88  19]\n",
      " [246 134]]\n",
      "done Test\n",
      "9 --------------------------------------\n",
      "testLabel unique:  {0: 409, 1: 99}\n",
      "done load data\n",
      "0.7618110236220472\n",
      "recall:  0.3434343434343434\n",
      "percision:  0.37777777777777777\n",
      "confusion_matrix: \n",
      " [[353  56]\n",
      " [ 65  34]]\n",
      "done Test\n",
      "10 --------------------------------------\n",
      "testLabel unique:  {0: 237, 1: 221}\n",
      "done load data\n",
      "0.6353711790393013\n",
      "recall:  0.3167420814479638\n",
      "percision:  0.813953488372093\n",
      "confusion_matrix: \n",
      " [[221  16]\n",
      " [151  70]]\n",
      "done Test\n",
      "11 --------------------------------------\n",
      "testLabel unique:  {0: 29, 1: 354}\n",
      "done load data\n",
      "0.7754569190600522\n",
      "recall:  0.7711864406779662\n",
      "percision:  0.9820143884892086\n",
      "confusion_matrix: \n",
      " [[ 24   5]\n",
      " [ 81 273]]\n",
      "done Test\n",
      "12 --------------------------------------\n",
      "testLabel unique:  {0: 245, 1: 243}\n",
      "done load data\n",
      "0.7745901639344263\n",
      "recall:  0.7037037037037037\n",
      "percision:  0.8181818181818182\n",
      "confusion_matrix: \n",
      " [[207  38]\n",
      " [ 72 171]]\n",
      "done Test\n",
      "13 --------------------------------------\n",
      "testLabel unique:  {0: 117, 1: 383}\n",
      "done load data\n",
      "0.556\n",
      "recall:  0.45430809399477806\n",
      "percision:  0.93048128342246\n",
      "confusion_matrix: \n",
      " [[104  13]\n",
      " [209 174]]\n",
      "done Test\n",
      "14 --------------------------------------\n",
      "testLabel unique:  {0: 117, 1: 344}\n",
      "done load data\n",
      "0.7570498915401301\n",
      "recall:  0.7587209302325582\n",
      "percision:  0.9\n",
      "confusion_matrix: \n",
      " [[ 88  29]\n",
      " [ 83 261]]\n",
      "done Test\n"
     ]
    }
   ],
   "source": [
    "for start in range(0, 15):\n",
    "    print(start, '--------------------------------------')\n",
    "    testRqa = []\n",
    "    testLabel = []\n",
    "    for iRecord in range(start, start+1):\n",
    "        rqa, label, _ = myUtil.loadRqa(recordNames[iRecord], 'test')\n",
    "        testRqa = np.append(testRqa, rqa, axis=0) if len(testRqa) > 0 else rqa\n",
    "        testLabel = np.append(testLabel, label, axis=0) if len(testLabel) > 0 else label\n",
    "    unique, count = np.unique(testLabel, return_counts=True)\n",
    "    print('testLabel unique: ', dict(zip(unique, count)))\n",
    "    print('done load data')\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "    pre = clf.predict(testRqa)\n",
    "    # print('pre: ', pre)\n",
    "    test = accuracy_score(testLabel, pre)\n",
    "    print(test)\n",
    "\n",
    "    print('recall: ', recall_score(testLabel, pre))\n",
    "    print('percision: ', precision_score(testLabel, pre))\n",
    "    print('confusion_matrix: \\n', confusion_matrix(testLabel, pre))\n",
    "    print('done Test')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done import\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src import config\n",
    "from src import MyUtil as myUtil\n",
    "print('done import')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record for train:  ['a01', 'a02', 'a04', 'a06', 'a07', 'a08', 'a09', 'a11', 'a12', 'a13', 'a14', 'a16', 'a17', 'a18', 'a20', 'b01', 'b02', 'b03', 'b04', 'b05', 'c01', 'c02', 'c03', 'c04', 'c05', 'c06', 'c07', 'c08', 'c09', 'c10']\n",
      "record for test:  ['a03', 'a05', 'a15', 'a10', 'a19']\n",
      "done load RQA\n"
     ]
    }
   ],
   "source": [
    "recordNames = config.NAME_OF_RECORD\n",
    "numRecord = len(recordNames)\n",
    "recordNameForTest = ['a03', 'a05', 'a15', 'a10', 'a19']\n",
    "trainRqa, trainLabel, testRqa, testLabel = myUtil.loadAllRqa(recordNameForTest)\n",
    "print('done load RQA')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainRqa:  (17456, 9)\n",
      "trainLabel:  (17456,)\n",
      "testRqa:  (2413, 9)\n",
      "testLabel:  (2413,)\n",
      "trainLabel unique:  {0: 11330, 1: 6126}\n",
      "testLabel unique:  {0: 1250, 1: 1163}\n"
     ]
    }
   ],
   "source": [
    "print('trainRqa: ', trainRqa.shape)\n",
    "# print(trainRqa[-10:])\n",
    "print('trainLabel: ', trainLabel.shape)\n",
    "print('testRqa: ', testRqa.shape)\n",
    "# print(testRqa[-10:])\n",
    "print('testLabel: ', testLabel.shape)\n",
    "\n",
    "unique, count = np.unique(trainLabel, return_counts=True)\n",
    "print('trainLabel unique: ', dict(zip(unique, count)))\n",
    "unique, count = np.unique(testLabel, return_counts=True)\n",
    "print('testLabel unique: ', dict(zip(unique, count)))#%%\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='tanh', early_stopping=True,\n",
      "              hidden_layer_sizes=(60, 100, 2), max_iter=500, random_state=1,\n",
      "              solver='sgd')\n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (60, 100, 2), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 500, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(activation='tanh', hidden_layer_sizes=(60, 100, 2), max_iter=500, alpha=0.0001,\n",
    "                    solver='sgd', random_state=1, validation_fraction=0.1, early_stopping=True)\n",
    "\n",
    "print(clf)\n",
    "clf.fit(trainRqa, trainLabel)\n",
    "print(clf.get_params())\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testLabel unique:  {0: 1250, 1: 1163}\n",
      "accuracy: 0.823\n",
      "recall: 0.709\n",
      "percision: 0.902\n",
      "confusion_matrix: \n",
      " [[1160   90]\n",
      " [ 338  825]]\n",
      "done Test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "pre = clf.predict(testRqa)\n",
    "accuracy = accuracy_score(testLabel, pre)\n",
    "unique, count = np.unique(testLabel, return_counts=True)\n",
    "print('testLabel unique: ', dict(zip(unique, count)))\n",
    "print(\"accuracy: %.3f\"%accuracy)\n",
    "print('recall: %.3f'%recall_score(testLabel, pre))\n",
    "print('percision: %.3f'%precision_score(testLabel, pre))\n",
    "print('confusion_matrix: \\n', confusion_matrix(testLabel, pre))\n",
    "# print('classification_report: \\n', classification_report(testLabel, pre))\n",
    "print('done Test')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a03\n",
      "testLabel unique:  {0: 266, 1: 245}\n",
      "accuracy: 0.857, recall: 0.743, percision: 0.948\n",
      "confusion_matrix: \n",
      " [[256  10]\n",
      " [ 63 182]]\n",
      "a05\n",
      "testLabel unique:  {0: 162, 1: 276}\n",
      "accuracy: 0.845, recall: 0.783, percision: 0.964\n",
      "confusion_matrix: \n",
      " [[154   8]\n",
      " [ 60 216]]\n",
      "a15\n",
      "testLabel unique:  {0: 117, 1: 344}\n",
      "accuracy: 0.748, recall: 0.689, percision: 0.963\n",
      "confusion_matrix: \n",
      " [[108   9]\n",
      " [107 237]]\n",
      "a10\n",
      "testLabel unique:  {0: 409, 1: 99}\n",
      "accuracy: 0.791, recall: 0.333, percision: 0.452\n",
      "confusion_matrix: \n",
      " [[369  40]\n",
      " [ 66  33]]\n",
      "a19\n",
      "testLabel unique:  {0: 296, 1: 199}\n",
      "accuracy: 0.869, recall: 0.789, percision: 0.872\n",
      "confusion_matrix: \n",
      " [[273  23]\n",
      " [ 42 157]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "for recordName in recordNameForTest:\n",
    "    print(recordName)\n",
    "    testRqa, testLabel, _ = myUtil.loadRqa(recordName, 'test')\n",
    "\n",
    "    unique, count = np.unique(testLabel, return_counts=True)\n",
    "    print('testLabel unique: ', dict(zip(unique, count)))\n",
    "\n",
    "    pre = clf.predict(testRqa)\n",
    "    accuracy = accuracy_score(testLabel, pre)\n",
    "    recall = recall_score(testLabel, pre)\n",
    "    precision = precision_score(testLabel, pre)\n",
    "    print(\"accuracy: {:.3f}, recall: {:.3f}, percision: {:.3f}\".format(accuracy, recall, precision))\n",
    "    print('confusion_matrix: \\n', confusion_matrix(testLabel, pre))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# allRqa = []\n",
    "# allLabel = []\n",
    "#\n",
    "# # for iRecord in range(0, numTrain):\n",
    "# for iRecord in range(10, numRecord):\n",
    "#     rqa, label, _ = myUtil.loadRqa(recordNames[iRecord], 'train')\n",
    "#     allRqa = np.append(trainRqa, rqa, axis=0) if len(trainRqa) > 0 else rqa\n",
    "#     allLabel = np.append(trainLabel, label, axis=0) if len(trainLabel) > 0 else label\n",
    "# print('done load')\n",
    "# X_embedded = np.load('backup.npy', allow_pickle=True)\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "# X_embedded = TSNE(n_components=2).fit_transform(allRqa)\n",
    "# print(X_embedded.shape)\n",
    "# np.save('backup2.npy', X_embedded)\n",
    "# print('done transform')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# print(X_embedded)\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# # print(transform[:, 0])\n",
    "#\n",
    "# # X_embedded = np.load('backup.npy', allow_pickle=True)\n",
    "# print('1')\n",
    "# normalX = X_embedded[np.where(allLabel == config.NORMAL_LABEL)]\n",
    "# print(allLabel)\n",
    "# normalIndex = np.where(allLabel == config.NORMAL_LABEL)\n",
    "# print(allLabel[np.where(allLabel == config.NORMAL_LABEL)])\n",
    "# print('---------------')\n",
    "# apneaX = X_embedded[np.where(allLabel == config.APNEA_LABEL)]\n",
    "# apneaIndex = np.where(allLabel == config.APNEA_LABEL)\n",
    "#\n",
    "# plt.scatter(normalX[:, 0], normalX[: ,1], color='green')\n",
    "# plt.scatter(apneaX[:, 0], apneaX[: ,1], color='red')\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
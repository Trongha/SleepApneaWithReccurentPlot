{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done import\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src import config\n",
    "from src import MyUtil as myUtil\n",
    "print('done import')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done load data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "recordNames = config.NAME_OF_RECORD\n",
    "numRecord = len(recordNames)\n",
    "numTrain = config.NUMBER_OF_TRAIN_RECORD\n",
    "trainRqa = []\n",
    "trainLabel = []\n",
    "\n",
    "# for iRecord in range(0, numTrain):\n",
    "for iRecord in range(10, numRecord):\n",
    "    rqa, label, _ = myUtil.loadRqa(recordNames[iRecord], 'train')\n",
    "    trainRqa = np.append(trainRqa, rqa, axis=0) if len(trainRqa) > 0 else rqa\n",
    "    trainLabel = np.append(trainLabel, label, axis=0) if len(trainLabel) > 0 else label\n",
    "\n",
    "testRqa = []\n",
    "testLabel = []\n",
    "for iRecord in range(0, 10):\n",
    "    rqa, label, _ = myUtil.loadRqa(recordNames[iRecord], 'test')\n",
    "    testRqa = np.append(testRqa, rqa, axis=0) if len(testRqa) > 0 else rqa\n",
    "    testLabel = np.append(testLabel, label, axis=0) if len(testLabel) > 0 else label\n",
    "print('done load data')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainRqa:  (15206, 12)\n",
      "trainLabel:  (15206,)\n",
      "testRqa:  (4604, 12)\n",
      "testLabel:  (4604,)\n",
      "trainLabel unique:  {0: 10837, 1: 4369}\n",
      "testLabel unique:  {0: 3628, 1: 976}\n"
     ]
    }
   ],
   "source": [
    "print('trainRqa: ', trainRqa.shape)\n",
    "# print(trainRqa[-10:])\n",
    "print('trainLabel: ', trainLabel.shape)\n",
    "print('testRqa: ', testRqa.shape)\n",
    "# print(testRqa[-10:])\n",
    "print('testLabel: ', testLabel.shape)\n",
    "\n",
    "unique, count = np.unique(trainLabel, return_counts=True)\n",
    "print('trainLabel unique: ', dict(zip(unique, count)))\n",
    "unique, count = np.unique(testLabel, return_counts=True)\n",
    "print('testLabel unique: ', dict(zip(unique, count)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done fit\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "# X, y = make_classification(n_samples=len(trainRqa), n_features=2,\n",
    "#                            n_informative=2, n_redundant=0,\n",
    "#                            random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(max_depth=6, n_estimators=100)\n",
    "clf.fit(trainRqa, trainLabel)\n",
    "\n",
    "print('done fit')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param:  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print('param: ', clf.get_params())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre:  [0 0 0 ... 0 0 0]\n",
      "0.8518679409209383\n",
      "recall:  0.45799180327868855\n",
      "percision:  0.745\n",
      "confusion_matrix: \n",
      " [[3475  153]\n",
      " [ 529  447]]\n",
      "done Test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "pre = clf.predict(testRqa)\n",
    "print('pre: ', pre)\n",
    "test = accuracy_score(testLabel, pre)\n",
    "print(test)\n",
    "\n",
    "print('recall: ', recall_score(testLabel, pre))\n",
    "print('percision: ', precision_score(testLabel, pre))\n",
    "print('confusion_matrix: \\n', confusion_matrix(testLabel, pre))\n",
    "print('done Test')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro'])\n",
      "fit_time \t [0.73565698 0.44185829]\n",
      "score_time \t [0.05285931 0.0488677 ]\n",
      "test_precision_macro \t [0.77890589 0.91904867]\n",
      "test_recall_macro \t [0.62157397 0.51955423]\n",
      "done cross validate\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "scores = cross_validate(clf, testRqa, testLabel, scoring=scoring, cv=2)\n",
    "print(scores.keys())\n",
    "for key in scores.keys():\n",
    "    print(key, '\\t', scores[key])\n",
    "# sorted(scores.keys())\n",
    "\n",
    "print('done cross validate')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done import\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src import config\n",
    "from src import MyUtil as myUtil\n",
    "print('done import')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done load data\n"
     ]
    }
   ],
   "source": [
    "recordNames = config.NAME_OF_RECORD\n",
    "numRecord = len(recordNames)\n",
    "numTrain = config.NUMBER_OF_TRAIN_RECORD\n",
    "trainRqa = []\n",
    "trainLabel = []\n",
    "\n",
    "# for iRecord in range(0, numTrain):\n",
    "for iRecord in range(10, numRecord):\n",
    "    rqa, label, _ = myUtil.loadRqa(recordNames[iRecord], 'train')\n",
    "    trainRqa = np.append(trainRqa, rqa, axis=0) if len(trainRqa) > 0 else rqa\n",
    "    trainLabel = np.append(trainLabel, label, axis=0) if len(trainLabel) > 0 else label\n",
    "\n",
    "testRqa = []\n",
    "testLabel = []\n",
    "for iRecord in range(0, 10):\n",
    "    rqa, label, _ = myUtil.loadRqa(recordNames[iRecord], 'test')\n",
    "    testRqa = np.append(testRqa, rqa, axis=0) if len(testRqa) > 0 else rqa\n",
    "    testLabel = np.append(testLabel, label, axis=0) if len(testLabel) > 0 else label\n",
    "print('done load data')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainRqa:  (15443, 9)\n",
      "trainLabel:  (15443,)\n",
      "testRqa:  (4407, 9)\n",
      "testLabel:  (4407,)\n",
      "trainLabel unique:  {0: 11013, 1: 4430}\n",
      "testLabel unique:  {0: 1722, 1: 2685}\n"
     ]
    }
   ],
   "source": [
    "print('trainRqa: ', trainRqa.shape)\n",
    "# print(trainRqa[-10:])\n",
    "print('trainLabel: ', trainLabel.shape)\n",
    "print('testRqa: ', testRqa.shape)\n",
    "# print(testRqa[-10:])\n",
    "print('testLabel: ', testLabel.shape)\n",
    "\n",
    "unique, count = np.unique(trainLabel, return_counts=True)\n",
    "print('trainLabel unique: ', dict(zip(unique, count)))\n",
    "unique, count = np.unique(testLabel, return_counts=True)\n",
    "print('testLabel unique: ', dict(zip(unique, count)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "done fit\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(trainRqa, trainLabel)\n",
    "print(clf)\n",
    "print('done fit')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre:  [1 1 1 ... 0 0 0]\n",
      "0.6707510778307239\n",
      "recall:  0.4823091247672253\n",
      "percision:  0.9550147492625368\n",
      "confusion_matrix: \n",
      " [[1661   61]\n",
      " [1390 1295]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.96      0.70      1722\n",
      "           1       0.96      0.48      0.64      2685\n",
      "\n",
      "    accuracy                           0.67      4407\n",
      "   macro avg       0.75      0.72      0.67      4407\n",
      "weighted avg       0.79      0.67      0.66      4407\n",
      "\n",
      "done Test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "pre = clf.predict(testRqa)\n",
    "print('pre: ', pre)\n",
    "test = accuracy_score(testLabel, pre)\n",
    "print(test)\n",
    "\n",
    "print('recall: ', recall_score(testLabel, pre))\n",
    "print('percision: ', precision_score(testLabel, pre))\n",
    "print('confusion_matrix: \\n', confusion_matrix(testLabel, pre))\n",
    "print('classification_report: \\n', classification_report(testLabel, pre))\n",
    "print('done Test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.42s/trial, best loss: 0.14956296536095826]\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.48s/trial, best loss: 0.14956296536095826]\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.39s/trial, best loss: 0.14956296536095826]\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.10s/trial, best loss: 0.14956296536095826]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.12trial/s, best loss: 0.14956296536095826]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.16trial/s, best loss: 0.14956296536095826]\n",
      "100%|██████████| 7/7 [00:04<00:00,  1.50trial/s, best loss: 0.14956296536095826]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78trial/s, best loss: 0.14956296536095826]\n",
      " 89%|████████▉ | 8/9 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator, extra_trees\n",
    "from hyperopt import tpe\n",
    "\n",
    "estim = HyperoptEstimator(classifier=clf,\n",
    "                          preprocessing=[],\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=10,\n",
    "                          trial_timeout=300)\n",
    "estim.fit(trainRqa, trainLabel)\n",
    "print('done fit')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pre = clf.predict(testRqa)\n",
    "print('pre: ', pre)\n",
    "test = accuracy_score(testLabel, pre)\n",
    "print(test)\n",
    "print('done Test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(clf.get_params())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
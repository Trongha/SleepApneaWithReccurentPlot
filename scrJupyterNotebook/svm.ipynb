{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done import\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src import config\n",
    "from src import MyUtil as myUtil\n",
    "print('done import')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record for train:  ['a01', 'a02', 'a04', 'a06', 'a07', 'a08', 'a09', 'a11', 'a12', 'a13', 'a14', 'a16', 'a17', 'a18', 'a20', 'b01', 'b02', 'b03', 'b04', 'b05', 'c01', 'c02', 'c03', 'c04', 'c05', 'c06', 'c07', 'c08', 'c09', 'c10']\n",
      "record for test:  ['a03', 'a05', 'a15', 'a10', 'a19']\n",
      "done load RQA\n"
     ]
    }
   ],
   "source": [
    "recordNames = config.NAME_OF_RECORD\n",
    "numRecord = len(recordNames)\n",
    "recordNameForTest = ['a03', 'a05', 'a15', 'a10', 'a19']\n",
    "trainRqa, trainLabel, testRqa, testLabel = myUtil.loadAllRqa(recordNameForTest)\n",
    "print('done load RQA')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainRqa:  (17456, 9)\n",
      "trainLabel:  (17456,)\n",
      "testRqa:  (2413, 9)\n",
      "testLabel:  (2413,)\n",
      "trainLabel unique:  {0: 11330, 1: 6126}\n",
      "testLabel unique:  {0: 1250, 1: 1163}\n"
     ]
    }
   ],
   "source": [
    "print('trainRqa: ', trainRqa.shape)\n",
    "# print(trainRqa[-10:])\n",
    "print('trainLabel: ', trainLabel.shape)\n",
    "print('testRqa: ', testRqa.shape)\n",
    "# print(testRqa[-10:])\n",
    "print('testLabel: ', testLabel.shape)\n",
    "\n",
    "unique, count = np.unique(trainLabel, return_counts=True)\n",
    "print('trainLabel unique: ', dict(zip(unique, count)))\n",
    "unique, count = np.unique(testLabel, return_counts=True)\n",
    "print('testLabel unique: ', dict(zip(unique, count)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "done fit\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(trainRqa, trainLabel)\n",
    "print(clf.get_params())\n",
    "# print(clf)\n",
    "print('done fit')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testLabel unique:  {0: 1250, 1: 1163}\n",
      "accuracy: 0.844\n",
      "recall: 0.767\n",
      "percision: 0.895\n",
      "confusion_matrix: \n",
      " [[1145  105]\n",
      " [ 271  892]]\n",
      "done Test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "pre = clf.predict(testRqa)\n",
    "accuracy = accuracy_score(testLabel, pre)\n",
    "unique, count = np.unique(testLabel, return_counts=True)\n",
    "print('testLabel unique: ', dict(zip(unique, count)))\n",
    "print(\"accuracy: %.3f\"%accuracy)\n",
    "print('recall: %.3f'%recall_score(testLabel, pre))\n",
    "print('percision: %.3f'%precision_score(testLabel, pre))\n",
    "print('confusion_matrix: \\n', confusion_matrix(testLabel, pre))\n",
    "# print('classification_report: \\n', classification_report(testLabel, pre))\n",
    "print('done Test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a03\n",
      "testLabel unique:  {0: 266, 1: 245}\n",
      "accuracy: 0.863, recall: 0.829, percision: 0.879\n",
      "confusion_matrix: \n",
      " [[238  28]\n",
      " [ 42 203]]\n",
      "a05\n",
      "testLabel unique:  {0: 162, 1: 276}\n",
      "accuracy: 0.831, recall: 0.779, percision: 0.943\n",
      "confusion_matrix: \n",
      " [[149  13]\n",
      " [ 61 215]]\n",
      "a15\n",
      "testLabel unique:  {0: 117, 1: 344}\n",
      "accuracy: 0.790, recall: 0.794, percision: 0.913\n",
      "confusion_matrix: \n",
      " [[ 91  26]\n",
      " [ 71 273]]\n",
      "a10\n",
      "testLabel unique:  {0: 409, 1: 99}\n",
      "accuracy: 0.841, recall: 0.374, percision: 0.661\n",
      "confusion_matrix: \n",
      " [[390  19]\n",
      " [ 62  37]]\n",
      "a19\n",
      "testLabel unique:  {0: 296, 1: 199}\n",
      "accuracy: 0.891, recall: 0.824, percision: 0.896\n",
      "confusion_matrix: \n",
      " [[277  19]\n",
      " [ 35 164]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "for recordName in recordNameForTest:\n",
    "    print(recordName)\n",
    "    testRqa, testLabel, _ = myUtil.loadRqa(recordName, 'test')\n",
    "\n",
    "    unique, count = np.unique(testLabel, return_counts=True)\n",
    "    print('testLabel unique: ', dict(zip(unique, count)))\n",
    "\n",
    "    pre = clf.predict(testRqa)\n",
    "    accuracy = accuracy_score(testLabel, pre)\n",
    "    recall = recall_score(testLabel, pre)\n",
    "    precision = precision_score(testLabel, pre)\n",
    "    print(\"accuracy: {:.3f}, recall: {:.3f}, percision: {:.3f}\".format(accuracy, recall, precision))\n",
    "    print('confusion_matrix: \\n', confusion_matrix(testLabel, pre))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre:  [1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "0.8909090909090909\n",
      "done Test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pre = clf.predict(testRqa)\n",
    "print('pre: ', pre)\n",
    "test = accuracy_score(testLabel, pre)\n",
    "print(test)\n",
    "print('done Test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "print(clf.get_params())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}